{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Columns description taken from this link:https://archive.ics.uci.edu/ml/datasets/wine+quality\n\n\n\n* Importing Libraries\n* For ML Models: sklearn\n* For Data Processing: numpy, pandas, sklearn\n* For Data Visualization: matplotlib, seaborn, plotly**","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#Importing libraries \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n \nfrom sklearn.linear_model import LinearRegression ,LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error ,mean_squared_error, median_absolute_error,confusion_matrix,accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC ,SVR\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data = pd.read_csv('/kaggle/input/wine-quality-dataset/WineQT.csv')\ndel Data['Id']\n#Data.drop(columns=\"Id\",inplace=True)\n#Data.drop('Id',axis=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Here I am subtracting 3 from the quality column to change the range of quality column from 3-8 to 0-5*","metadata":{}},{"cell_type":"code","source":"Data['quality'] = Data['quality']-3\nData","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data.head(10).style.background_gradient(cmap='Reds')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data.sample(10).style.background_gradient(cmap='Reds')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data.describe().T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data.describe().T.style.background_gradient(cmap = 'Blues')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data.mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Exploratory Data Analysis(EDA)","metadata":{}},{"cell_type":"code","source":"Data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data.duplicated().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data.drop_duplicates(inplace = True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data.duplicated().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data['quality'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nData.plot()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data.hist(bins=20, figsize=(10, 10))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.bar(Data['quality'], Data['alcohol'])\nplt.xlabel('quality')\nplt.ylabel('alcohol')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 5))\nsns.boxplot(data=Data[Data.columns[4:8]])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 10))\nsns.heatmap(Data.corr(), cbar=True, square=True, fmt='.2f', annot=True, cmap='rainbow')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 12))\nsns.heatmap(Data.corr() > 0.6, cbar=False, square=True, fmt='.2f', annot=True, annot_kws={'size':10}, cmap='Greens')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above heat map we can conclude that the ‘total sulphur dioxide’ and ‘free sulphur dioxide‘ are highly correlated features so, we will remove them","metadata":{}},{"cell_type":"code","source":"Data = Data.drop('total sulfur dioxide', axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Building a ML Model \n","metadata":{}},{"cell_type":"code","source":"X = Data.drop(columns=\"quality\")           \ny = Data[\"quality\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split the data train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\nnorm = MinMaxScaler()\nx_train = norm.fit_transform(X_train)\nx_test = norm.fit_transform(X_test)\n\nprint(\"X Train : \", X_train.shape)\nprint(\"X Test  : \", X_test.shape)\nprint(\"Y Train : \", y_train.shape)\nprint(\"Y Test  : \", y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# using the model Logistic Regression\n\n","metadata":{}},{"cell_type":"code","source":"\nLo_model=LogisticRegression(solver='liblinear')\n\n\nLo_model.fit(X_train,y_train)\n\n\n\nprint(\"Score the X-train with Y-train is : \", Lo_model.score(X_train,y_train))\nprint(\"Score the X-test  with Y-test  is : \", Lo_model.score(X_test,y_test))\n\ny_pred_Lo=Lo_model.predict(X_test)\n\nprint( \" Model Evaluation Logistic R : mean absolute error is \", mean_absolute_error(y_test,y_pred_Lo))\nprint(\" Model Evaluation Logistic R : mean squared  error is \" , mean_squared_error(y_test,y_pred_Lo))\nprint(\" Model Evaluation Logistic R : median absolute error is \" ,median_absolute_error(y_test,y_pred_Lo)) \n\nprint(\" Model Evaluation Logistic R : accuracy score \" , accuracy_score(y_test,y_pred_Lo))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# using the model Decision Tree Classifier\n","metadata":{}},{"cell_type":"code","source":"Tree_model=DecisionTreeClassifier(max_depth=50)\nTree_model.fit(X_train,y_train)\n\nprint(\"Score the X-train with Y-train is : \", Tree_model.score(X_train,y_train))\nprint(\"Score the X-test  with Y-test  is : \", Tree_model.score(X_test,y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select  Important columns\n\nprint(\"The Important columns \\n\",Tree_model.feature_importances_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data.head(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note, the feature importances for quality in the DecisionTree , column Alcohol = 19% ,we said in analysis\n","metadata":{}},{"cell_type":"code","source":"print(\"The classes \",Tree_model.classes_)\n\ny_pred_T =Tree_model.predict(X_test)\n\nprint(\" Model Evaluation Decision Tree : accuracy score \" , accuracy_score(y_test,y_pred_T))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# using the model SVC","metadata":{}},{"cell_type":"code","source":"svc_model=SVC(C=50,kernel=\"rbf\")\n\nsvc_model.fit(X_train,y_train)\n\ny_pred_svc =svc_model.predict(X_test)\n\nprint(\"Score the X-train with Y-train is : \", svc_model.score(X_train,y_train))\nprint(\"Score the X-test  with Y-test  is : \", svc_model.score(X_test,y_test))\nprint(\" Model Evaluation Decision Tree : accuracy score \" , accuracy_score(y_test,y_pred_svc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# using the model SVR","metadata":{}},{"cell_type":"code","source":"svr_model=SVR(degree=1,coef0=1, tol=0.001, C=1.5,epsilon=0.001)\n\nsvr_model.fit(X_train,y_train)\n\ny_pred_svr =svc_model.predict(X_test)\n\nprint(\"Score the X-train with Y-train is : \", svr_model.score(X_train,y_train))\nprint(\"Score the X-test  with Y-test  is : \", svr_model.score(X_test,y_test))\nprint(\" Model Evaluation Decision Tree : accuracy score \" , accuracy_score(y_test,y_pred_svr))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# using the model K Neighbors Classifier\n# ","metadata":{}},{"cell_type":"code","source":"\nK_model = KNeighborsClassifier(n_neighbors = 8)\nK_model.fit(X_train, y_train)\n\ny_pred_k = K_model.predict(X_test)\n\nprint(\"Score the X-train with Y-train is : \", K_model.score(X_train,y_train))\nprint(\"Score the X-test  with Y-test  is : \", K_model.score(X_test,y_test))\nprint(\" Model Evaluation K Neighbors Classifier : accuracy score \" , accuracy_score(y_test,y_pred_k))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The End \n Thank for reading my analysis , if you any questions or advice me please write in the comment ","metadata":{}},{"cell_type":"markdown","source":"# Vote\nIf you liked my workvote me","metadata":{}}]}